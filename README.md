# xFarm â€“ CSV Processing Pipeline with Terraform

## ğŸ“Œ Architecture Overview

This project provisions a simple and secure AWS-based pipeline using Terraform. The architecture responds to a common data ingestion use case:

- ğŸ“¤ A CSV file is uploaded to an **S3 Bucket**
- âš¡ That triggers an **AWS Lambda** function
- ğŸ” The Lambda processes the file contents (e.g., reads or parses it)

## ğŸ› ï¸ Technologies

- **Terraform** (local backend)
- **AWS Lambda** (Python 3.12)
- **S3 with event triggers**
- **IAM Roles (least privilege)**

---

## ğŸš€ Deployment Instructions

### 1. Clone the repo

git clone git@github.com:zunderStake/xFarm.git

cd xFarm

### 2. Package the Lambda function
cd lambda
zip ../lambda_function_payload.zip handler.py
cd ..

### 3. Initialize and deploy
terraform init
terraform plan
terraform apply

---

## âš™ï¸Environment Configuration
All variables are defined in terraform.tfvars, like:

- **bucket_name = "xfarm-csv-processing-bucket"**
- **lambda_name = "xfarmCsvProcessor"**
- **lambda_zip_path = "lambda_function_payload.zip"**

## ğŸ” Security Best Practices Applied

- Least privilege IAM role for Lambda
- S3 versioning and server-side encryption (AES-256)
- Modularized Terraform code (clean structure)
- Environment variables supported via Terraform

## ğŸ“¦ Project Structure
â”œâ”€â”€ lambda/                  â†’ Python function<br>
â”œâ”€â”€ modules/<br>
â”‚   â”œâ”€â”€ iam/                 â†’ IAM role & policies<br>
â”‚   â”œâ”€â”€ lambda/              â†’ Lambda + permissions<br>
â”‚   â””â”€â”€ s3/                  â†’ S3 bucket + event trigger<br>
â”œâ”€â”€ main.tf<br>
â”œâ”€â”€ variables.tf<br>
â”œâ”€â”€ outputs.tf<br>
â”œâ”€â”€ terraform.tfvars<br>
â””â”€â”€ README.md
